{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de02b217",
   "metadata": {},
   "source": [
    "## GRPO + LoRA Without Regret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b2ee9",
   "metadata": {},
   "source": [
    "### Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016509a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -qqq trl peft math-verify latex2sympy2_extended trackio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930e4f35",
   "metadata": {},
   "source": [
    "### Load Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044bf81a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from latex2sympy2_extended import NormalizationConfig\n",
    "from math_verify import LatexExtractionConfig, parse, verify\n",
    "from trl import (\n",
    "    GRPOConfig,\n",
    "    GRPOTrainer,\n",
    "    ModelConfig,\n",
    "    get_peft_config,\n",
    "    get_quantization_config,\n",
    "    get_kbit_device_map,\n",
    ")\n",
    "\n",
    "os.environ[\"TRACKIO_SPACE_ID\"] = \"trl-lora-without-regret\"\n",
    "os.environ[\"TRACKIO_PROJECT\"] = \"trl-lora-without-regret\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d3abcb",
   "metadata": {},
   "source": [
    "### Load Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b54fa6d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_config = ModelConfig(\n",
    "    model_name_or_path=\"Qwen/Qwen3-0.6B\",\n",
    "    torch_dtype=\"bfloat16\",\n",
    "    use_peft=True,\n",
    "    lora_r=1,\n",
    "    lora_alpha=32,\n",
    "    lora_target_modules=\"all-linear\",\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    output_dir=\"./grpo-lora-qwen3\",\n",
    "    learning_rate=1e-6,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=100,\n",
    "    gradient_checkpointing=True,\n",
    "    num_generations=8,\n",
    "    generation_batch_size=8,\n",
    "    max_prompt_length=2048,\n",
    "    max_completion_length=1024,\n",
    "    logging_steps=10,\n",
    "    save_steps=50,\n",
    "    report_to=[\"trackio\"],\n",
    "    bf16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce069be7",
   "metadata": {},
   "source": [
    "### Load Data From Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ba533",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"HuggingFaceH4/OpenR1-Math-220k-default-verified\", split=\"train\")\n",
    "dataset = dataset.select(range(min(5000, len(dataset))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3467dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def make_conversation(example):\n",
    "    return {\"prompt\": [{\"role\": \"user\", \"content\": example[\"problem\"]}]}\n",
    "\n",
    "\n",
    "dataset = dataset.map(make_conversation)\n",
    "dataset = dataset.remove_columns(\n",
    "    [col for col in dataset.column_names if col not in [\"prompt\", \"solution\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6710117d",
   "metadata": {},
   "source": [
    "### Reward Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee71b1a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def strip_reasoning_accuracy_reward(\n",
    "    completions: list[list[dict[str, str]]], solution: list[str], **kwargs\n",
    ") -> list[Optional[float]]:\n",
    "    contents = [completion[0][\"content\"] for completion in completions]\n",
    "    rewards = []\n",
    "\n",
    "    for content, sol in zip(contents, solution):\n",
    "        while \"<think>\" in content and \"</think>\" in content:\n",
    "            start = content.find(\"<think>\")\n",
    "            end = content.find(\"</think>\", start)\n",
    "            if start != -1 and end != -1:\n",
    "                content = content[:start] + content[end + len(\"</think>\") :]\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        gold_parsed = parse(\n",
    "            f\"${sol}$\",\n",
    "            extraction_config=[\n",
    "                LatexExtractionConfig(\n",
    "                    boxed_match_priority=0, try_extract_without_anchor=True\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        if len(gold_parsed) != 0:\n",
    "            # We require the answer to be provided in correct latex (no malformed operators)\n",
    "            answer_parsed = parse(\n",
    "                content,\n",
    "                extraction_config=[\n",
    "                    LatexExtractionConfig(\n",
    "                        boxed_match_priority=0,\n",
    "                        normalization_config=NormalizationConfig(\n",
    "                            basic_latex=True,\n",
    "                            units=True,\n",
    "                            malformed_operators=False,\n",
    "                            nits=False,\n",
    "                            boxed=True,\n",
    "                        ),\n",
    "                        try_extract_without_anchor=False,\n",
    "                    )\n",
    "                ],\n",
    "                extraction_mode=\"first_match\",\n",
    "            )\n",
    "            try:\n",
    "                reward = float(verify(gold_parsed, answer_parsed))\n",
    "            except:\n",
    "                reward = None\n",
    "        else:\n",
    "            reward = None\n",
    "\n",
    "        rewards.append(reward)\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2591116a",
   "metadata": {},
   "source": [
    "### Intialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdca96f6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dtype = (\n",
    "    getattr(torch, model_config.torch_dtype)\n",
    "    if model_config.torch_dtype not in [\"auto\", None]\n",
    "    else model_config.torch_dtype\n",
    ")\n",
    "training_args.model_init_kwargs = {\n",
    "    \"torch_dtype\": dtype,\n",
    "    \"device_map\": get_kbit_device_map(),\n",
    "    \"quantization_config\": get_quantization_config(model_config),\n",
    "}\n",
    "\n",
    "peft_config = get_peft_config(model_config)\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model=model_config.model_name_or_path,\n",
    "    args=training_args,\n",
    "    reward_funcs=[strip_reasoning_accuracy_reward],\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756fd1f1",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7041dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0191db1f",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485b71dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca26c9f",
   "metadata": {},
   "source": [
    "### Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d481357",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_config.model_name_or_path, torch_dtype=dtype, device_map=\"auto\"\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, training_args.output_dir)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_config.model_name_or_path)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4074951e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def test_model(problem: str, max_new_tokens: int = 512):\n",
    "    messages = [{\"role\": \"user\", \"content\": problem}]\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs, max_new_tokens=max_new_tokens, temperature=0.7, do_sample=True\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(\n",
    "        outputs[0][inputs[\"input_ids\"].shape[1] :], skip_special_tokens=True\n",
    "    )\n",
    "\n",
    "\n",
    "# Test on first example\n",
    "example = dataset[0]\n",
    "result = test_model(example[\"prompt\"][0][\"content\"])\n",
    "print(f\"Problem: {example['prompt'][0]['content'][:200]}...\")\n",
    "print(f\"\\nResponse: {result[:500]}...\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
